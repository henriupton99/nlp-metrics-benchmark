{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test metrics on Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# FUNCTIONS / CLASSES :\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append(\"./code\")\n",
    "from metrics import *\n",
    "from data_processing import WMT22, dataset\n",
    "\n",
    "# Fast metrics :\n",
    "metrics_1 = [BLEU,\n",
    "           Sacre_BLEU,\n",
    "           ROUGE_1,\n",
    "           ROUGE_L,\n",
    "           ROUGE_S4,\n",
    "           CHRF,\n",
    "           CHRF_1,\n",
    "           CHRF_pp,\n",
    "           METEOR,\n",
    "           WER,\n",
    "           TER]\n",
    "\n",
    "# Energivore metrics :   \n",
    "metrics_2 =[#INFO_LM,\n",
    "            BARY,\n",
    "            DEPTH,\n",
    "            MOVER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = \"Je me présente je m'appelle Henri\"\n",
    "good_candidate = \"Je me présente je me prénomme Henri\"\n",
    "avg_candidate = \"Bonjour mon nom est Henri\"\n",
    "bad_candidate = \"J'aime les pizzas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRIC :  BLEU\n",
      "good candidate :  0.7142857313156128\n",
      "avg candidate :  0.16374613344669342\n",
      "bad candidate :  0.0\n",
      "TIME :  -0.0006916250022186432\n",
      "METRIC :  Sacre_BLEU\n",
      "good candidate :  0.7142857313156128\n",
      "avg candidate :  0.16374613344669342\n",
      "bad candidate :  0.0\n",
      "TIME :  0.000244709004618926\n",
      "METRIC :  ROUGE_1\n",
      "good candidate :  0.7058823704719543\n",
      "avg candidate :  0.1538461595773697\n",
      "bad candidate :  0.0\n",
      "TIME :  0.00019208400044590235\n",
      "METRIC :  ROUGE_L\n",
      "good candidate :  0.7058823704719543\n",
      "avg candidate :  0.1538461595773697\n",
      "bad candidate :  0.0\n",
      "TIME :  1.5124998753890395e-05\n",
      "METRIC :  ROUGE_S4\n",
      "good candidate :  0.5142857142857143\n",
      "avg candidate :  0.0\n",
      "bad candidate :  0.0\n",
      "TIME :  3.129199831164442e-05\n",
      "METRIC :  CHRF\n",
      "good candidate :  0.6306954117328964\n",
      "avg candidate :  0.15168410023582476\n",
      "bad candidate :  0.08836230975871608\n",
      "TIME :  0.00025741699937498197\n",
      "METRIC :  CHRF_1\n",
      "good candidate :  0.6301317811012268\n",
      "avg candidate :  0.15004166960716248\n",
      "bad candidate :  0.08252978324890137\n",
      "TIME :  0.00024174999998649582\n",
      "METRIC :  CHRF_pp\n",
      "good candidate :  0.6441160440444946\n",
      "avg candidate :  0.1384241133928299\n",
      "bad candidate :  0.06970440596342087\n",
      "TIME :  0.0004840830006287433\n",
      "METRIC :  METEOR\n",
      "good candidate :  0.6098360655737705\n",
      "avg candidate :  0.0847457627118644\n",
      "bad candidate :  0.0\n",
      "TIME :  -0.0004305830007069744\n",
      "METRIC :  WER\n",
      "good candidate :  0.6666666567325592\n",
      "avg candidate :  0.1666666865348816\n",
      "bad candidate :  0.0\n",
      "TIME :  -0.00024745799964875914\n",
      "METRIC :  TER\n",
      "good candidate :  0.6666666567325592\n",
      "avg candidate :  0.1666666865348816\n",
      "bad candidate :  0.0\n",
      "TIME :  9.25839995034039e-05\n"
     ]
    }
   ],
   "source": [
    "for metric in metrics_1:\n",
    "    start = timeit.timeit()\n",
    "    print(\"METRIC : \", str(metric.__name__))\n",
    "    print(\"good candidate : \", metric(reference = reference, candidate = good_candidate))\n",
    "    print(\"avg candidate : \", metric(reference = reference, candidate = avg_candidate))\n",
    "    print(\"bad candidate : \", metric(reference = reference, candidate = bad_candidate))\n",
    "    end = timeit.timeit()\n",
    "    print(\"TIME : \", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute metrics for WMT22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_WMT22 = dataset(set_name = \"WMT22\", sample_size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "('ende',\n 'Sie können jederzeit zurückkehren, da unser Chat-Service-Fenster rund um die Uhr geöffnet ist',\n 'Sie können jederzeit wiederkommen, da unser Chat-Service-Fenster täglich rund um die Uhr geöffnet ist',\n 'conversation',\n 1,\n 0.0)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_WMT22.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 168.51it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 297.87it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 130.87it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  4.17it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 327.32it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00, 10.61it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 185.74it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 86.23it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 97.40it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  2.88it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 107.02it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 108.47it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 161.47it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 119.73it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 207.85it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 193.38it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  4.36it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 138.52it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 267.89it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 120.08it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  4.55it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 95.83it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00, 10.72it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 233.87it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00, 11.00it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 342.78it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00, 20.43it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 355.12it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 240.72it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00, 15.59it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 365.93it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 327.86it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 229.99it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 165.34it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  2.27it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 164.45it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 100.58it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 135.72it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 106.91it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 116.41it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 106.77it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  2.65it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 188.14it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 155.58it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 147.31it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 149.30it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 129.62it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  2.55it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 157.06it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 121.80it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 157.21it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00, 13.61it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 268.61it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  3.30it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 408.01it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 202.84it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 76.16it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  9.11it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 253.55it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  4.20it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 123.59it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  3.82it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 98.20it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  7.70it/s]\n",
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 173.82it/s]\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s]\n",
      "  0%|          | 47/15000 [01:31<8:05:49,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device :  cpu\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zj/yy0y_jv108d6b5knbv8vjwkr0000gn/T/ipykernel_3353/765383794.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m metrics_scores = compute_metrics(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mset_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"WMT22\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msample_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./data/metrics_scores_2.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/project_nlp/./code/metrics.py\u001b[0m in \u001b[0;36mcompute_metrics\u001b[0;34m(set_name, metrics, sample_size, path)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mgold_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gold_score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/project_nlp/./code/metrics.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hyp, ref)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m def compute_metrics(\n",
      "\u001b[0;32m~/Desktop/project_nlp/./code/metrics.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m def compute_metrics(\n",
      "\u001b[0;32m~/Desktop/project_nlp/./code/metrics.py\u001b[0m in \u001b[0;36mDEPTH\u001b[0;34m(reference, candidate)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0mmetric_call_depth_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_idfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetric_call_depth_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'depth_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nlg_eval_via_simi_measures/depth_score.py\u001b[0m in \u001b[0;36mevaluate_batch\u001b[0;34m(self, batch_hyps, batch_refs, idf_hyps, idf_ref)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;31m###############################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mbatch_refs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_refs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mbatch_refs_embeddings_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_refs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mbatch_hyps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_hyps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1345\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1348\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         )\n\u001b[0;32m-> 1014\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1015\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    601\u001b[0m                 )\n\u001b[1;32m    602\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    604\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metrics_scores = compute_metrics(\n",
    "    set_name = \"WMT22\",\n",
    "    metrics = metrics_2,\n",
    "    sample_size = 5000,\n",
    "    path = \"./data/metrics_scores_2.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_scores = pd.read_csv(\n",
    "    \"./data/metrics_scores_1.csv\",\n",
    "    index_col = \"gold_score\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sltl</th>\n      <th>hyp</th>\n      <th>ref</th>\n      <th>domain</th>\n      <th>seg_id</th>\n      <th>BLEU</th>\n      <th>Sacre_BLEU</th>\n      <th>ROUGE_1</th>\n      <th>ROUGE_L</th>\n      <th>ROUGE_S4</th>\n      <th>CHRF</th>\n      <th>CHRF_1</th>\n      <th>CHRF_pp</th>\n      <th>METEOR</th>\n      <th>WER</th>\n      <th>TER</th>\n    </tr>\n    <tr>\n      <th>gold_score</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0.386671</th>\n      <td>enru</td>\n      <td>Если команда продолжит впечатлять криптосообще...</td>\n      <td>Если команда продолжит удивлять криптосообщест...</td>\n      <td>news</td>\n      <td>455</td>\n      <td>0.079948</td>\n      <td>-0.092873</td>\n      <td>1.424038</td>\n      <td>1.567528</td>\n      <td>0.034862</td>\n      <td>0.129633</td>\n      <td>0.260829</td>\n      <td>0.111884</td>\n      <td>-0.083722</td>\n      <td>0.100819</td>\n      <td>0.077665</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "            sltl                                                hyp  \\\ngold_score                                                            \n0.386671    enru  Если команда продолжит впечатлять криптосообще...   \n\n                                                          ref domain  seg_id  \\\ngold_score                                                                     \n0.386671    Если команда продолжит удивлять криптосообщест...   news     455   \n\n                BLEU  Sacre_BLEU   ROUGE_1   ROUGE_L  ROUGE_S4      CHRF  \\\ngold_score                                                                 \n0.386671    0.079948   -0.092873  1.424038  1.567528  0.034862  0.129633   \n\n              CHRF_1   CHRF_pp    METEOR       WER       TER  \ngold_score                                                    \n0.386671    0.260829  0.111884 -0.083722  0.100819  0.077665  "
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_scores.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_scores.drop([\"BLEU\", \"Sacre_BLEU\", \"ROUGE_1\", \"ROUGE_L\", \"ROUGE_S4\",\n",
    "                     \"CHRF\", \"CHRF_1\", \"CHRF_pp\", \"METEOR\"], axis = 1).to_csv(\"./data/edit_based_metrics_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_scores.drop([\"WER\", \"TER\"], axis = 1).to_csv(\"./data/ngram_based_metrics_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gold_score</th>\n      <th>sltl</th>\n      <th>hyp</th>\n      <th>ref</th>\n      <th>domain</th>\n      <th>seg_id</th>\n      <th>WER</th>\n      <th>TER</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.386671</td>\n      <td>ende</td>\n      <td>Sie können jederzeit zurückkehren, da unser Ch...</td>\n      <td>Sie können jederzeit wiederkommen, da unser Ch...</td>\n      <td>conversation</td>\n      <td>1</td>\n      <td>0.358519</td>\n      <td>0.335239</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.386671</td>\n      <td>ende</td>\n      <td>Ich hoffe sehr, dass Sie eine Lösung finden</td>\n      <td>Ich hoffe wirklich, dass Sie eine Lösung finde...</td>\n      <td>conversation</td>\n      <td>2</td>\n      <td>0.301252</td>\n      <td>0.278000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.386671</td>\n      <td>ende</td>\n      <td>Vielen Dank, dass Sie #PRS_ORG# kontaktiert ha...</td>\n      <td>Vielen Dank, dass Sie #PRS_ORG# kontaktiert ha...</td>\n      <td>conversation</td>\n      <td>3</td>\n      <td>0.076767</td>\n      <td>0.101705</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.386671</td>\n      <td>ende</td>\n      <td>Ich wünsche Ihnen einen schönen Abend.</td>\n      <td>Ich wünsche Ihnen noch einen schönen Abend.</td>\n      <td>conversation</td>\n      <td>4</td>\n      <td>0.358519</td>\n      <td>0.335239</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.117933</td>\n      <td>ende</td>\n      <td>Der Iran meldet die niedrigste Anzahl tägliche...</td>\n      <td>Iran meldet niedrigste Zahl täglicher COVID-19...</td>\n      <td>news</td>\n      <td>5</td>\n      <td>0.100819</td>\n      <td>0.077665</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>99721</th>\n      <td>0.386671</td>\n      <td>zhen</td>\n      <td>The exercise achievements have been confirmed ...</td>\n      <td>The results of the exercise have won recogniti...</td>\n      <td>news</td>\n      <td>1871</td>\n      <td>-0.115648</td>\n      <td>-0.138698</td>\n    </tr>\n    <tr>\n      <th>99722</th>\n      <td>0.117933</td>\n      <td>zhen</td>\n      <td>Ruan Xiongsheng, the director of the Exercise ...</td>\n      <td>Ruan Xiongsheng, Director of the Exercise Guid...</td>\n      <td>news</td>\n      <td>1872</td>\n      <td>0.358519</td>\n      <td>0.369582</td>\n    </tr>\n    <tr>\n      <th>99723</th>\n      <td>0.386671</td>\n      <td>zhen</td>\n      <td>The achievements made from exercise proved spe...</td>\n      <td>The achievements made from the exercise proved...</td>\n      <td>news</td>\n      <td>1873</td>\n      <td>0.401469</td>\n      <td>0.378168</td>\n    </tr>\n    <tr>\n      <th>99724</th>\n      <td>0.386671</td>\n      <td>zhen</td>\n      <td>According to Chen Chunming, leader of Guidance...</td>\n      <td>According to Chen Chunming, leader of Guidance...</td>\n      <td>news</td>\n      <td>1874</td>\n      <td>0.259562</td>\n      <td>0.265178</td>\n    </tr>\n    <tr>\n      <th>99725</th>\n      <td>0.386671</td>\n      <td>zhen</td>\n      <td>During the exercise period, Chinese People’s L...</td>\n      <td>During the exercise, Chinese People’s Liberati...</td>\n      <td>news</td>\n      <td>1875</td>\n      <td>0.389443</td>\n      <td>0.366148</td>\n    </tr>\n  </tbody>\n</table>\n<p>99726 rows × 8 columns</p>\n</div>",
      "text/plain": "       gold_score  sltl                                                hyp  \\\n0        0.386671  ende  Sie können jederzeit zurückkehren, da unser Ch...   \n1        0.386671  ende        Ich hoffe sehr, dass Sie eine Lösung finden   \n2        0.386671  ende  Vielen Dank, dass Sie #PRS_ORG# kontaktiert ha...   \n3        0.386671  ende             Ich wünsche Ihnen einen schönen Abend.   \n4        0.117933  ende  Der Iran meldet die niedrigste Anzahl tägliche...   \n...           ...   ...                                                ...   \n99721    0.386671  zhen  The exercise achievements have been confirmed ...   \n99722    0.117933  zhen  Ruan Xiongsheng, the director of the Exercise ...   \n99723    0.386671  zhen  The achievements made from exercise proved spe...   \n99724    0.386671  zhen  According to Chen Chunming, leader of Guidance...   \n99725    0.386671  zhen  During the exercise period, Chinese People’s L...   \n\n                                                     ref        domain  \\\n0      Sie können jederzeit wiederkommen, da unser Ch...  conversation   \n1      Ich hoffe wirklich, dass Sie eine Lösung finde...  conversation   \n2      Vielen Dank, dass Sie #PRS_ORG# kontaktiert ha...  conversation   \n3            Ich wünsche Ihnen noch einen schönen Abend.  conversation   \n4      Iran meldet niedrigste Zahl täglicher COVID-19...          news   \n...                                                  ...           ...   \n99721  The results of the exercise have won recogniti...          news   \n99722  Ruan Xiongsheng, Director of the Exercise Guid...          news   \n99723  The achievements made from the exercise proved...          news   \n99724  According to Chen Chunming, leader of Guidance...          news   \n99725  During the exercise, Chinese People’s Liberati...          news   \n\n       seg_id       WER       TER  \n0           1  0.358519  0.335239  \n1           2  0.301252  0.278000  \n2           3  0.076767  0.101705  \n3           4  0.358519  0.335239  \n4           5  0.100819  0.077665  \n...       ...       ...       ...  \n99721    1871 -0.115648 -0.138698  \n99722    1872  0.358519  0.369582  \n99723    1873  0.401469  0.378168  \n99724    1874  0.259562  0.265178  \n99725    1875  0.389443  0.366148  \n\n[99726 rows x 8 columns]"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit = pd.read_csv(\"./data/edit_based_metrics_scores.csv\")\n",
    "edit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}