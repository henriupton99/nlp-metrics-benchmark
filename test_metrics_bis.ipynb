{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "481684e7-f873-4505-8e31-cef025d52ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# FUNCTIONS / CLASSES :\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append(\"./code\")\n",
    "sys.path.append(\"/home/guillot/Documents/Robin Ensae/Matières/ML for NLP/nlg_eval_via_simi_measures/nlg_eval_via_simi_measures\")\n",
    "\n",
    "from data_processing import WMT22, dataset\n",
    "from metrics_bis import Sacre_BLEU, ROUGE_1, ROUGE_L, CHRF, CHRF_1, CHRF_pp, TER, TER_asian, INFO_LM \n",
    "from bary_score import BaryScoreMetric\n",
    "from depth_score import DepthScoreMetric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afdcfbc4-2921-4ea3-bd89-caae82ade4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = \"Je me présente je m'appelle Henri\"\n",
    "good_candidate = \"Je me présente je me prénomme Henri\"\n",
    "avg_candidate = \"Bonjour mon nom est Henri\"\n",
    "bad_candidate = \"J'aime les pizzas\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf96cf7-9584-4006-8418-0fce9c224b96",
   "metadata": {},
   "source": [
    "## SACRE-BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca0ede70-672c-464c-9ff2-17bc1b067f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7054014205932617\n",
      "0.1666666567325592\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(Sacre_BLEU(good_candidate,reference))\n",
    "print(Sacre_BLEU(avg_candidate,reference))\n",
    "print(Sacre_BLEU(bad_candidate,reference))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f9907d-6ce8-4c6b-8f15-51a1a4c5e716",
   "metadata": {},
   "source": [
    "## ROUGE-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48ff297a-a0af-4804-8867-5e777792d9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7058823704719543\n",
      "0.1538461595773697\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(ROUGE_1(good_candidate,reference))\n",
    "print(ROUGE_1(avg_candidate,reference))\n",
    "print(ROUGE_1(bad_candidate,reference))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a940c127-cc49-42f1-8621-83a16c8c78ac",
   "metadata": {},
   "source": [
    "## ROUGE-L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "334da13a-f61b-4da2-b515-0c723005cbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7058823704719543\n",
      "0.1538461595773697\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(ROUGE_L(good_candidate,reference))\n",
    "print(ROUGE_L(avg_candidate,reference))\n",
    "print(ROUGE_L(bad_candidate,reference))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a94745d-8a27-48a8-988d-18a0ffa636f0",
   "metadata": {},
   "source": [
    "## CHRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e293ab37-4ca1-4d3d-8177-74735324c91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6140276789665222\n",
      "0.18641690909862518\n",
      "0.13485760986804962\n"
     ]
    }
   ],
   "source": [
    "print(CHRF(good_candidate,reference))\n",
    "print(CHRF(avg_candidate,reference))\n",
    "print(CHRF(bad_candidate,reference))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a31b59b-fc38-4eae-a830-7799cd33a783",
   "metadata": {},
   "source": [
    "## CHRF-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33281b03-5d60-4102-8afe-3784369c6472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6301317811012268\n",
      "0.15004166960716248\n",
      "0.08252978324890137\n"
     ]
    }
   ],
   "source": [
    "print(CHRF_1(good_candidate,reference))\n",
    "print(CHRF_1(avg_candidate,reference))\n",
    "print(CHRF_1(bad_candidate,reference))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c270e1ae-265a-4fe2-814a-48f9ac559347",
   "metadata": {},
   "source": [
    "## CHRF++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66fbd6fe-3e0a-448f-8d70-9a23ac5f3b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.617087721824646\n",
      "0.16385114192962646\n",
      "0.10114321112632751\n"
     ]
    }
   ],
   "source": [
    "print(CHRF_pp(good_candidate,reference))\n",
    "print(CHRF_pp(avg_candidate,reference))\n",
    "print(CHRF_pp(bad_candidate,reference))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779287e2-f4b9-4977-bcbb-fd663b7f9352",
   "metadata": {},
   "source": [
    "## TER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0613f82d-e961-45c4-8ca5-8a5d88207809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2857142984867096\n",
      "1.0\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "print(TER(good_candidate,reference))\n",
    "print(TER(avg_candidate,reference))\n",
    "print(TER(bad_candidate,reference))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e983f11f-6510-4bcc-a304-3bbb07763278",
   "metadata": {},
   "source": [
    "## TER_Asian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5cc57f1a-7124-4681-930a-e1a9ec7f39eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2857142984867096\n",
      "1.0\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "print(TER_asian(good_candidate,reference))\n",
    "print(TER_asian(avg_candidate,reference))\n",
    "print(TER_asian(bad_candidate,reference))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2c3f14-fd27-46be-903d-18602fea672b",
   "metadata": {},
   "source": [
    "## INFO_LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a92e94f-94bf-4430-a945-a3a2d2c434de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 28.0/28.0 [00:00<00:00, 3.69kB/s]\n",
      "Downloading: 100%|██████████| 570/570 [00:00<00:00, 69.2kB/s]\n",
      "Downloading: 100%|██████████| 232k/232k [00:03<00:00, 75.0kB/s] \n",
      "Downloading: 100%|██████████| 466k/466k [00:02<00:00, 211kB/s] \n",
      "Downloading: 100%|██████████| 440M/440M [01:25<00:00, 5.13MB/s] \n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.83s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-11.103135108947754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.14s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-20.30190658569336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.19s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-12.437806129455566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(INFO_LM(good_candidate,reference))\n",
    "print(INFO_LM(avg_candidate,reference))\n",
    "print(INFO_LM(bad_candidate,reference))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
