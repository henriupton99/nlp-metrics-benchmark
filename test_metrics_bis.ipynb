{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51079b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS / CLASSES :\n",
    "from transformers import logging\n",
    "\n",
    "logging.set_verbosity_warning()\n",
    "\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append(\"./code\")\n",
    "\n",
    "from data_processing import WMT22, dataset\n",
    "from metrics import Sacre_BLEU, ROUGE_1, ROUGE_L, ROUGE_S4, CHRF, CHRF_1, CHRF_pp, METEOR, WACC, TER, INFO_LM, BERT, BARY, DEPTH, MOVER  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f4f2ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "139aa45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = \"Je me présente je m'appelle Henri\"\n",
    "good_candidate = \"Je me présente je me prénomme Henri\"\n",
    "avg_candidate = \"Bonjour mon nom est Henri\"\n",
    "bad_candidate = \"J'aime les pizzas\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1041bf0f",
   "metadata": {},
   "source": [
    "## SACRE-BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4a80d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7142857313156128\n",
      "0.16374613344669342\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(Sacre_BLEU(reference, good_candidate))\n",
    "print(Sacre_BLEU(reference, avg_candidate))\n",
    "print(Sacre_BLEU(reference, bad_candidate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5362bc",
   "metadata": {},
   "source": [
    "## ROUGE-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1393de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7058823704719543\n",
      "0.1538461595773697\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(ROUGE_1(reference, good_candidate))\n",
    "print(ROUGE_1(reference, avg_candidate))\n",
    "print(ROUGE_1(reference, bad_candidate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8985ced9",
   "metadata": {},
   "source": [
    "## ROUGE-L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5484c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7058823704719543\n",
      "0.1538461595773697\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(ROUGE_L(reference, good_candidate))\n",
    "print(ROUGE_L(reference, avg_candidate))\n",
    "print(ROUGE_L(reference, bad_candidate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665a3f79-2f05-42bc-a784-b197674abf64",
   "metadata": {},
   "source": [
    "## ROUGE-S4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfa14d00-fe5c-4111-8de1-ded457150755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5142857142857143\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(ROUGE_S4(reference, good_candidate))\n",
    "print(ROUGE_S4(reference, avg_candidate))\n",
    "print(ROUGE_S4(reference, bad_candidate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fea80a",
   "metadata": {},
   "source": [
    "## CHRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3cc1a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6306954117328964\n",
      "0.15168410023582476\n",
      "0.08836230975871608\n"
     ]
    }
   ],
   "source": [
    "print(CHRF(reference, good_candidate))\n",
    "print(CHRF(reference, avg_candidate))\n",
    "print(CHRF(reference, bad_candidate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d6df00",
   "metadata": {},
   "source": [
    "## CHRF-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f40c264",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guillot/anaconda3/lib/python3.8/site-packages/torchmetrics/functional/text/chrf.py:181: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  total_n_grams[n] = tensor(sum(n_grams_counts[n].values()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6301317811012268\n",
      "0.15004166960716248\n",
      "0.08252978324890137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guillot/anaconda3/lib/python3.8/site-packages/torchmetrics/functional/text/chrf.py:208: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  matching_n_grams[n] = tensor(\n"
     ]
    }
   ],
   "source": [
    "print(CHRF_1(reference, good_candidate))\n",
    "print(CHRF_1(reference, avg_candidate))\n",
    "print(CHRF_1(reference, bad_candidate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3982d3fa",
   "metadata": {},
   "source": [
    "## CHRF++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4775985b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6441160440444946\n",
      "0.1384241133928299\n",
      "0.06970440596342087\n"
     ]
    }
   ],
   "source": [
    "print(CHRF_pp(reference, good_candidate))\n",
    "print(CHRF_pp(reference, avg_candidate))\n",
    "print(CHRF_pp(reference, bad_candidate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908df453-7072-4aae-8a5d-2a0076ecd87c",
   "metadata": {},
   "source": [
    "## METEOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "127aac15-00ba-43b5-a5ff-71e1f1a90ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6098360655737705\n",
      "0.0847457627118644\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(METEOR(reference, good_candidate))\n",
    "print(METEOR(reference, avg_candidate))\n",
    "print(METEOR(reference, bad_candidate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff16a281-02f1-4e77-9a9a-ec5b3e7fb724",
   "metadata": {},
   "source": [
    "## WACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f025e01-0f14-4ea1-b557-3249987bd10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666567325592\n",
      "0.1666666865348816\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(WACC(reference, good_candidate))\n",
    "print(WACC(reference, avg_candidate))\n",
    "print(WACC(reference, bad_candidate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329f63d2",
   "metadata": {},
   "source": [
    "## TER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21e852e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666567325592\n",
      "0.1666666865348816\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(TER(reference, good_candidate))\n",
    "print(TER(reference, avg_candidate))\n",
    "print(TER(reference, bad_candidate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89761644",
   "metadata": {},
   "source": [
    "## INFO_LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e00bc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3269243240356445\n",
      "1.7963107824325562\n",
      "1.446884036064148\n"
     ]
    }
   ],
   "source": [
    "# computes a dissimilarity score between the reference and the candidate\n",
    "\n",
    "print(INFO_LM(reference, good_candidate))\n",
    "print(INFO_LM(reference, avg_candidate))\n",
    "print(INFO_LM(reference, bad_candidate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d06302",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75978c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8046869039535522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6578395962715149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6479260325431824\n"
     ]
    }
   ],
   "source": [
    "print(BERT(reference, good_candidate))\n",
    "print(BERT(reference, avg_candidate))\n",
    "print(BERT(reference, bad_candidate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba70a25f",
   "metadata": {},
   "source": [
    "## BARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e27c471",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BaryScore Progress:   0%|          | 0/1 [00:00<?, ?it/s]/home/guillot/anaconda3/lib/python3.8/site-packages/ot/bregman.py:517: UserWarning: Sinkhorn did not converge. You might want to increase the number of iterations `numItermax` or the regularization parameter `reg`.\n",
      "  warnings.warn(\"Sinkhorn did not converge. You might want to \"\n",
      "/home/guillot/anaconda3/lib/python3.8/site-packages/ot/bregman.py:484: RuntimeWarning: overflow encountered in true_divide\n",
      "  v = b / KtransposeU\n",
      "/home/guillot/anaconda3/lib/python3.8/site-packages/ot/bregman.py:492: UserWarning: Warning: numerical errors at iteration 3\n",
      "  warnings.warn('Warning: numerical errors at iteration %d' % ii)\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27713123984450183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BaryScore Progress:   0%|          | 0/1 [00:00<?, ?it/s]/home/guillot/anaconda3/lib/python3.8/site-packages/ot/bregman.py:484: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  v = b / KtransposeU\n",
      "/home/guillot/anaconda3/lib/python3.8/site-packages/ot/bregman.py:492: UserWarning: Warning: numerical errors at iteration 0\n",
      "  warnings.warn('Warning: numerical errors at iteration %d' % ii)\n",
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5556842414295818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BaryScore Progress: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5534571492040994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# computes a distance between two empirical distributions induces by the reference and the candidate respectively\n",
    "\n",
    "print(BARY(reference,good_candidate))\n",
    "print(BARY(reference,avg_candidate))\n",
    "print(BARY(reference,bad_candidate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0f7f82",
   "metadata": {},
   "source": [
    "## DEPTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f859193f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 51.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3646968832720779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 82.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7445472963192743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Depth Score Progress: 100%|██████████| 1/1 [00:00<00:00, 79.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7300219785917436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# computes a distance between two empirical distributions induces by the reference and the candidate respectively\n",
    "\n",
    "print(DEPTH(reference, good_candidate))\n",
    "print(DEPTH(reference, avg_candidate))\n",
    "print(DEPTH(reference, bad_candidate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cfd9bb-aec1-4906-b6fb-0dd1d26cfff0",
   "metadata": {},
   "source": [
    "## MOVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a464b96-8e4c-466f-93ac-98fda3fb6831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6917208298715033\n",
      "0.5808445806855468\n",
      "0.5589217391934899\n"
     ]
    }
   ],
   "source": [
    "print(MOVER(reference, good_candidate))\n",
    "print(MOVER(reference, avg_candidate))\n",
    "print(MOVER(reference, bad_candidate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
